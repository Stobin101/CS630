{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-f4410afa1500>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-f4410afa1500>\"\u001b[1;36m, line \u001b[1;32m8\u001b[0m\n\u001b[1;33m    Our goal is to gain a bit more familiarity with the way you might generate datasets from APIs or from a larger CSV.\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Data Visualization\n",
    "## Lab 3: Acquiring and Processing Data\n",
    "\n",
    "### Name: [Cole!!!                     ...and Tobin]\n",
    "\n",
    "# **Directions:** Throughout this notebook, add markdown cells as needed in order to document your process of trying to understand it.  I don't expect to just see three perfect answers and no explanations.  Tell me what you are trying!  In the end, make sure your cell and kernel linearities line up (that is, make sure that your final product can be followed from top to bottom).\n",
    "\n",
    "Our goal is to gain a bit more familiarity with the way you might generate datasets from APIs or from a larger CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Maps Geocoding API\n",
    "\n",
    "Below is a function that generates a random Latitude and Longitude in Wyoming (it's a [particularly square state](https://www.mapsofworld.com/usa/states/wyoming/wyoming-maps/wyoming-lat-long-map.jpg)).  **Your first goal** is to use the Google Maps Geocoding API to create a dataset of 10 random locations in Wyoming and the town and zip code they lie in.  For example:\n",
    "```\n",
    "[{\"lat\": \"44.952055\", \"lon\": \"-107.67753\", \"town\": \"Parkman\", \"zip\": \"82838\"}, ...]\n",
    "```\n",
    "\n",
    "To do this: \n",
    "\n",
    "1. [Get a google maps geocoding API key](https://developers.google.com/maps/documentation/geocoding/get-api-key) -- It's free and quick, just tell them the name of your \"app\" (it can be anything)\n",
    "2. [Take a look at how to use the geocoding API](https://developers.google.com/maps/documentation/geocoding/start) -- You're looking for the process they call \"reverse geocoding\"\n",
    "3. Build your request\n",
    "4. Interpret the result: it's a JSON response with tons of extra data so let me help you: you'll need `your_request_response_object.json()`.  Just grab the first result's `address_components` and dive into that array, or look for the results `formatted_address` and find the town and zip code in the resulting string (try `my_string.split(,)`.)\n",
    "5. Save the data as a [JSON file](https://docs.python.org/2/library/json.html) (or [use pandas](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_json.html), possibly easier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'44.2495,-108.8228'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_lat_long():\n",
    "    \"\"\" Generate a random latitude and longitude in Wyoming. \n",
    "    Bounds: 41째N to 45째N and 104.05째W to 111.05째W\n",
    "    \"\"\"\n",
    "    s= \"{},{}\".format(round(random.uniform(41, 45), 5), round(random.uniform(-111.05,-104.05), 5))\n",
    "    return s\n",
    "generate_lat_long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       lats       longs                       towns       zips\n",
      "0  41.16191  -104.18754                 Pine Bluffs   WY 82082\n",
      "1   41.2179  -105.27729                    Cheyenne   WY 82009\n",
      "2  41.60459  -107.68737                     Rawlins   WY 82301\n",
      "3  43.10694  -109.50805                        Cora   WY 82925\n",
      "4  41.94003  -110.63334                    Kemmerer   WY 83101\n",
      "5  41.08624  -104.87907                    Cheyenne   WY 82007\n",
      "6  43.35292  -106.08228                     Douglas   WY 82633\n",
      "7  42.96854  -108.84234                      Lander   WY 82520\n",
      "8  41.60236  -106.35008                Elk Mountain   WY 82324\n",
      "9  44.80505  -110.96571   Yellowstone National Park   WY 82190\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.DataFrame(columns = ['lats','longs','towns','zips'])\n",
    "\n",
    "for k in range(0,10):\n",
    "    l = generate_lat_long()\n",
    "    r = requests.get(\"https://maps.googleapis.com/maps/api/geocode/json?latlng=\" + l + \"&key=AIzaSyBmNNRuvZCKEiz-069QZh3PIV7Z_4RJ1Tc\")\n",
    "    latlong = l.split(',')\n",
    "    lat = latlong[0]\n",
    "    long = latlong[1]\n",
    "    data_string = r.json()\n",
    "    colelist = []\n",
    "    colelist = data_string['results'][0]['formatted_address'].split(',')\n",
    "    town = colelist[1]\n",
    "    zipcode = colelist[2]\n",
    "    data.loc[len(data.index)] = [lat, long, town, zipcode]\n",
    "    \n",
    "print(data)\n",
    "\n",
    "    # read it in again to not lose the first line of data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing a dataset using pandas\n",
    "\n",
    "[This CSV](http://introcs.cs.princeton.edu/java/data/bnc-wordfreq.csv) contains word frequencies in a subset of the British National Corpus, a 100 million long collect\n",
    "\n",
    "Questions/tasks for you:\n",
    "1. How many words are in this dataset?\n",
    "2. Construct the dataset consisting of all nouns whose frequency is greater than 20000 and which contain an \"`ag`\" in them.  Some hints: use pandas [boolean slicing](https://pandas.pydata.org/pandas-docs/stable/indexing.html#boolean-indexing); pandas can help you with [string containment](https://pandas.pydata.org/pandas-docs/stable/text.html#testing-for-strings-that-match-or-contain-a-pattern), too.\n",
    "3. Construct the dataset of all the prime-number-indexed rows.  Use [`.loc`](https://pandas.pydata.org/pandas-docs/stable/indexing.html#basics)\n",
    "\n",
    "Both of the datasets may be just constructed in memory, _i.e._ no need to save them to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6318\n",
      "      RANK  FREQUENCY        WORD PART OF SPEECH\n",
      "137    399      25340         age              n\n",
      "3118   462      22117    language              n\n",
      "3354   470      21884  management              n\n",
      "5301   503      20586       stage              n\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abbey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abolition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>above</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         WORD\n",
       "2       abbey\n",
       "3     ability\n",
       "5    abnormal\n",
       "7   abolition\n",
       "11      above"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "r = requests.get(\"http://introcs.cs.princeton.edu/java/data/bnc-wordfreq.csv\")\n",
    "#column_names = ['RANK','FREQUENCY','WORD','PART OF SPEECH']\n",
    "df = pd.read_csv(StringIO(r.text))\n",
    "df.head()\n",
    "# data = pd.DataFrame(columns = ['FREQUENCY','WORD','PART OF SPEECH'])\n",
    "# pd.Series(['FREQUENCY','WORD','PART OF SPEECH']).str.contains(pattern)\n",
    "\n",
    "print(df.shape[0])\n",
    "\n",
    "\n",
    "dataset_nouns = df.loc[(df['PART OF SPEECH'] == 'n')&]\n",
    "dataset_20000 = dataset_nouns.loc[df['FREQUENCY']>20000]\n",
    "dataset_ag = dataset_20000.loc[df['WORD'].str.contains('ag')]\n",
    "print(dataset_ag)\n",
    "\n",
    "\n",
    "dataset_primes = []\n",
    "\n",
    "for k in range(0,df.shape[0]): \n",
    "    dataset_primes.append(is_prime(k))\n",
    "\n",
    "newdata=df.loc[dataset_primes,[\"WORD\", ]]\n",
    "newdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2        True\n",
       "3        True\n",
       "4       False\n",
       "5       False\n",
       "6       False\n",
       "7        True\n",
       "8        True\n",
       "9       False\n",
       "10      False\n",
       "11      False\n",
       "12      False\n",
       "13      False\n",
       "14      False\n",
       "15      False\n",
       "16       True\n",
       "17      False\n",
       "18      False\n",
       "19      False\n",
       "20      False\n",
       "21       True\n",
       "22      False\n",
       "23      False\n",
       "24       True\n",
       "25      False\n",
       "26      False\n",
       "27       True\n",
       "28       True\n",
       "29      False\n",
       "        ...  \n",
       "6288    False\n",
       "6289     True\n",
       "6290     True\n",
       "6291    False\n",
       "6292    False\n",
       "6293    False\n",
       "6294     True\n",
       "6295     True\n",
       "6296     True\n",
       "6297     True\n",
       "6298     True\n",
       "6299    False\n",
       "6300    False\n",
       "6301     True\n",
       "6302    False\n",
       "6303    False\n",
       "6304    False\n",
       "6305    False\n",
       "6306    False\n",
       "6307    False\n",
       "6308     True\n",
       "6309    False\n",
       "6310    False\n",
       "6311    False\n",
       "6312     True\n",
       "6313    False\n",
       "6314    False\n",
       "6315    False\n",
       "6316     True\n",
       "6317     True\n",
       "Name: PART OF SPEECH, Length: 6318, dtype: bool"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['PART OF SPEECH'] == 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_prime(n):\n",
    "  if n == 2 or n == 3: return True\n",
    "  if n < 2 or n%2 == 0: return False\n",
    "  if n < 9: return True\n",
    "  if n%3 == 0: return False\n",
    "  r = int(n**0.5)\n",
    "  f = 5\n",
    "  while f <= r:\n",
    "    if n%f == 0: return False\n",
    "    if n%(f+2) == 0: return False\n",
    "    f +=6\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 False\n",
      "1 False\n",
      "2 True\n",
      "3 True\n",
      "4 False\n",
      "5 True\n",
      "6 False\n",
      "7 True\n",
      "8 False\n",
      "9 False\n",
      "10 False\n",
      "11 True\n",
      "12 False\n",
      "13 True\n",
      "14 False\n",
      "15 False\n",
      "16 False\n",
      "17 True\n",
      "18 False\n",
      "19 True\n",
      "20 False\n",
      "21 False\n",
      "22 False\n",
      "23 True\n",
      "24 False\n",
      "25 False\n",
      "26 False\n",
      "27 False\n",
      "28 False\n",
      "29 True\n",
      "30 False\n",
      "31 True\n",
      "32 False\n",
      "33 False\n",
      "34 False\n",
      "35 False\n",
      "36 False\n",
      "37 True\n",
      "38 False\n",
      "39 False\n",
      "40 False\n",
      "41 True\n",
      "42 False\n",
      "43 True\n",
      "44 False\n",
      "45 False\n",
      "46 False\n",
      "47 True\n",
      "48 False\n",
      "49 False\n",
      "50 False\n",
      "51 False\n",
      "52 False\n",
      "53 True\n",
      "54 False\n",
      "55 False\n",
      "56 False\n",
      "57 False\n",
      "58 False\n",
      "59 True\n",
      "60 False\n",
      "61 True\n",
      "62 False\n",
      "63 False\n",
      "64 False\n",
      "65 False\n",
      "66 False\n",
      "67 True\n",
      "68 False\n",
      "69 False\n",
      "70 False\n",
      "71 True\n",
      "72 False\n",
      "73 True\n",
      "74 False\n",
      "75 False\n",
      "76 False\n",
      "77 False\n",
      "78 False\n",
      "79 True\n",
      "80 False\n",
      "81 False\n",
      "82 False\n",
      "83 True\n",
      "84 False\n",
      "85 False\n",
      "86 False\n",
      "87 False\n",
      "88 False\n",
      "89 True\n",
      "90 False\n",
      "91 False\n",
      "92 False\n",
      "93 False\n",
      "94 False\n",
      "95 False\n",
      "96 False\n",
      "97 True\n",
      "98 False\n",
      "99 False\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(i, is_prime(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Analysis\n",
    "\n",
    "The task of taking text data and making it usable is tricky and can sometimes be time consuming.  Today, we'll keep it pretty simple.\n",
    "\n",
    "1. First, open the text file [`raven.txt`](https://cs.andover.edu/~nzufelt/dataviz/raven.txt), and copy its contents into a single string.\n",
    "2. Then, remove any character that isn't a letter, `\\n`, or (perhaps!) punctuation.  (hint: `\"a\" in \"cat\"` is `True` in Python, whereas `\"&\" in \"cat\"` is `False`.)\n",
    "3. `split` the text by \"sentence\" (more likely by line for this particular text file).  The \"sentences\" will become the rows of your dataset, and the occurance of certain words will be your columns.  It might help to further `split` your sentences by word.\n",
    "4. Create a dataset from this based upon whether the words `of`, `nothing`, `raven`, and/or `chamber` appear in each sentence: each entry in your dataset will be `0` (this word/column **not** in this sentence/row) or `1` (this word/column appears in this sentence/row).\n",
    "5. Output your dataset to a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"raven.txt\", \"r\") as f:\n",
    "#     r = requests.get('https://cs.andover.edu/~nzufelt/dataviz/raven.txt')\n",
    "    text = f.read()\n",
    "import re\n",
    "text = re.sub('[^A-Za-z&\\'\\n ]', '', text)\n",
    "lines = text.split('\\n')\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.DataFrame(columns = ['of','nothing','raven','chamber'])\n",
    "for k in range(0,len(lines)):\n",
    "    containsOf = 0\n",
    "    containsNothing = 0\n",
    "    containsRaven = 0\n",
    "    containsChamber =0\n",
    "    if 'of' in lines[k]:\n",
    "        containsOf = 1\n",
    "    if 'nothing' in lines[k]:\n",
    "        containsNothing = 1\n",
    "    if 'raven' in lines[k]:\n",
    "        containsRaven = 1\n",
    "    if 'chamber' in lines[k]:\n",
    "        containsChamber = 1\n",
    "    data.loc[len(data.index)] = [containsOf, containsNothing, containsRaven, containsChamber]\n",
    "\n",
    "data\n",
    "data.to_csv('RavenWords.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
